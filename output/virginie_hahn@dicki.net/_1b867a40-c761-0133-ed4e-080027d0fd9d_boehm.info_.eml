Date: Tue, 08 Mar 2016 13:41:26 +0000
From: Emmalee Zboncak II <kenneth.rosenbaum@boehm.info>
To: virginie_hahn@dicki.net
Message-ID: <1b867a40-c761-0133-ed4e-080027d0fd9d@boehm.info>
Subject: How HiveContext of spark internally works?
Mime-Version: 1.0
Content-Type: multipart/alternative;
 boundary="--==_mimepart_56ded611f0ded_118541a29ae9362d";
 charset=UTF-8
Content-Transfer-Encoding: 7bit


----==_mimepart_56ded611f0ded_118541a29ae9362d
Content-Type: text/plain;
 charset=UTF-8
Content-Transfer-Encoding: 7bit

I am new to Spark.I found using HiveContext we can connect to hive and run HiveQLs. I run it and it worked. 

My doubt is whether Spark does it through spark jobs .That is, it uses HiveContext only for accessing corresponding hive table files from HDFS 

Or 

It internally calls hive to execute the query?
----==_mimepart_56ded611f0ded_118541a29ae9362d
Content-Type: text/html;
 charset=UTF-8
Content-Transfer-Encoding: 7bit

<p>I am new to Spark.I found using <code>HiveContext</code> we can connect to <code>hive</code> and run <code>HiveQL</code>s. I run it and it worked. </p>

<p>My doubt is whether <code>Spark</code> does it through <code>spark jobs</code> .That is, it uses <code>HiveContext</code> only for accessing corresponding hive table files from HDFS </p>

<p>Or </p>

<p>It internally calls hive to execute the query?</p>
----==_mimepart_56ded611f0ded_118541a29ae9362d--
